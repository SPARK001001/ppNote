**Spark 基础：** 了解 Spark 的核心概念，如 RDD（Resilient Distributed Dataset）、DAG（Directed Acyclic Graph）等。理解 Spark 如何将数据分割成分布式的数据集，并进行转换和操作。

- 当涉及 Spark 的基础知识时，确保掌握以下核心概念：

  1. **RDD（Resilient Distributed Dataset）：** RDD 是 Spark 的核心数据抽象，代表了分布式的、不可变的数据集合。RDD 可以容错地存储在集群的多台机器上，提供了并行计算和数据操作的能力。可以通过从现有数据集进行转换（例如映射、过滤、合并等）来创建 RDD，也可以从外部存储（如 HDFS、本地文件系统）加载数据。

  2. **转换操作：** 转换操作是对 RDD 进行转换的操作，例如 `map()`、`filter()`、`reduceByKey()` 等。转换操作不会立即计算结果，而是构建了一个有向无环图（DAG），表示一系列的转换操作。

  3. **动作操作：** 动作操作会触发实际的计算，例如 `count()`、`collect()`、`reduce()` 等。动作操作会从根据之前构建的 DAG 开始计算，生成最终的结果。

  4. **DAG（Directed Acyclic Graph）：** DAG 是一个有向无环图，表示了一系列的转换操作，以及这些操作之间的依赖关系。Spark 在执行动作操作时，会根据 DAG 对转换操作进行优化并执行。

  5. **惰性求值：** Spark 使用惰性求值，意味着转换操作不会立即执行，只有在执行动作操作时才会触发计算。这种方式允许 Spark 进行优化并有效地计算。

  6. **持久化：** 为了避免多次计算同一 RDD，可以使用 `persist()` 或 `cache()` 将 RDD 缓存在内存或磁盘上，以便多次复用。

  7. **分区：** RDD 中的数据会被划分为一系列的分区，分布在集群的多台机器上。分区是 Spark 并行计算的基本单位。

  8. **依赖关系：** RDD 之间的转换操作会创建父子关系，分为窄依赖和宽依赖。窄依赖表示子 RDD 的分区只依赖于一个父 RDD 的分区，宽依赖表示子 RDD 的分区依赖于多个父 RDD 的分区。

  了解并掌握这些核心概念将有助于您理解 Spark 如何工作以及如何利用其进行数据处理和分布式计算。