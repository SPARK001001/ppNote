Apache Spark 是一个用于大规模数据处理的快速、通用的分布式计算框架。它提供了一系列高级 API，可以用于数据处理、机器学习、图计算等各种任务。以下是一些 Apache Spark 的主要考点：

1. **Spark 基础：** 了解 Spark 的核心概念，如 RDD（Resilient Distributed Dataset）、DAG（Directed Acyclic Graph）等。理解 Spark 如何将数据分割成分布式的数据集，并进行转换和操作。

2. **Spark 部署模式：** 理解 Spark 支持的不同部署模式，包括本地模式、集群模式（Standalone、YARN、Kubernetes）等，以及如何选择合适的部署模式。

3. **Spark SQL：** 理解 Spark SQL 的概念，以及如何使用 DataFrame 和 SQL 进行结构化数据处理。了解 Catalyst 查询优化器的作用。

4. **Spark Streaming：** 了解 Spark Streaming 的流式数据处理能力，如何将实时数据分成小批次进行处理，以及如何与其他流处理系统集成。

5. **Spark MLlib：** 理解 Spark MLlib（机器学习库）的功能，包括分类、回归、聚类、推荐等机器学习算法。

6. **GraphX：** 了解 Spark 的图计算库 GraphX，用于图分析和图算法的开发。

7. **Spark 数据格式：** 知道 Spark 支持的数据格式，如 Parquet、Avro、JSON、CSV 等，以及如何在 Spark 中读取和写入这些格式的数据。

8. **Spark 调优和性能优化：** 了解 Spark 中的性能优化技巧，包括数据分区、广播变量、持久化等，以及如何利用 Spark UI 进行性能分析。

9. **Spark 集成：** 了解 Spark 如何与其他大数据生态系统组件集成，如 Hadoop HDFS、Hive、HBase、Kafka 等。

10. **Spark 扩展：** 了解 Spark 的扩展库，如 Spark Streaming、SparkR、Spark on Kubernetes 等。

11. **Spark 应用场景：** 了解 Spark 在各种应用场景中的应用，如数据清洗、数据分析、机器学习模型训练等。

总之，Apache Spark 是一个广泛使用的大数据处理框架，具有强大的功能和性能。在进行 Spark 相关的学习和考试准备时，需要深入理解其核心概念和特性，以及如何在实际项目中应用。